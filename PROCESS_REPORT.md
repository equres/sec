# Process Report

The purpose of this file is to answer the below questions:

- is cron with downloading running properly
- are we getting new ZIP files downloaded daily already
- when we unzip, how do we know what's been unzipped already, and which files are new
- size of sec dest estimate
- size of unzipped finds: total, only indexable ones, other ones (JPEG etc)
- can we start indexing files from the disk already?
- how fast is indexing indexable files -- show me some logs. I don't care about per file speed. I care about in 30 or 60s, how many files are we inserting
- what's the estimate time going from 0 to all indexable files indexed in a DB


## Is cron with downloading running properly?

There are three main cron jobs that should run:

1. Backup to FTP
2. Generating the Stats for AWStats
3. Downloading and indexing the data and ZIP files

The second cron job does not work. The last stats file that was generated was on 22nd of Dec (which was NOT generated by a cron job but by us running the command directly on the terminal)

The third one seems to work based on the old files. Meaning the downloading ran but index did not. Nonetheless, the past week it has ran every day but the status is set as "failed"

## Are we getting new ZIP files downloaded daily

The problem is currently with the cron job (#3 mentioned above). Once that one is fixed, downloaded should be up and running properly

## When we unzip, how do we know what's been unzipped already, and which files are new

In the function `s.CreateFilesFromZIP` we actually check if the file that needs to be created exists already or needs to be created. It also checks if the file size is correct, if not, then it updates the file content

## Size of `dest` estimate

The size of ZIP files to be downloaded is `41.7 GB` while the raw file downloadables size is `853.9 GB`

The current `cache/` directory is around `45 GB` which seems correct based on the dest (this includes the index files, raw files downloaded using `dow data` and also ticker files)

## Size of unzipped finds: total, only indexable ones, other ones (JPEG etc)

The total unzipped directory is at `588 GB` even though it needs to be at `853.9 GB`

The indexable files of type `.htm` are at `178 GB` 
The indexable files of type `.xml` are at `396 GB`
The non-indexable files are at `14 GB`

## Can we start indexing files from the disk already?

For some reason, the unzipped files size does not equal the size mentioned in the XML files, once that is fixed, then we have index properly

## How fast is indexing indexable files

Ran the command and calculated the inserted rows 4 times and each with sleep time of 60 seconds:

`Run 1: 11,078 - 9,290 = 1788 Rows / 60s = 29.8 Rows per second`

`Run 2: 15,192 - 13,544 = 1648 Rows / 60s = 27.46 Rows per second`

`Run 3: 18,465 - 16,789 = 1676 Rows / 60s = 27.93 Rows per second`

`Run 4: 23,944 - 22,190 = 1754 Rows / 60s = 29.23 Rows per second`

Average of these 4 runs is `28.6 Rows per seconnd`

## What's the estimate time going from 0 to all indexable files indexed in a DB

As of now, we have 3,115,212 Rows that need to be indexed. Depending on the calculation above, this would take around 108,923.5 seconds, 1815.4 Minutes, or 30.25 Hours
